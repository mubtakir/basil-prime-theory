#!/usr/bin/env python3
"""
Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ÙŠÙ† Ø·Ø±ÙŠÙ‚ØªÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØªÙŠÙ†
Final Comparison Between Main Prediction Methods

Ø£Ø³ØªØ§Ø° Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù‡Ø§Ø¦ÙŠØ©: Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù…Ø­Ø³Ù†Ø©
"""

import numpy as np
import matplotlib.pyplot as plt
from basil_prime_theory import BasilPrimeTheory, generate_primes
from enhanced_prediction_algorithm import EnhancedPrimePrediction
import time
from typing import Dict, List, Tuple
import pandas as pd

class FinalMethodsComparison:
    """Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø·Ø±ÙŠÙ‚ØªÙŠÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØªÙŠÙ†"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©"""
        self.enhanced_predictor = EnhancedPrimePrediction()
    
    def method_basic(self, prime: int) -> Dict:
        """Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: BasilPrimeTheory Basic"""
        theory = BasilPrimeTheory(prime)
        start_time = time.time()
        prediction = theory.predict_next_prime(method='basic')
        execution_time = time.time() - start_time
        
        return {
            'method': 'Basic Method',
            'predicted_next': prediction['predicted_next'],
            'confidence': prediction['confidence'],
            'execution_time': execution_time
        }
    
    def method_enhanced(self, prime: int) -> Dict:
        """Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©: BasilPrimeTheory Enhanced"""
        theory = BasilPrimeTheory(prime)
        start_time = time.time()
        prediction = theory.predict_next_prime(method='enhanced')
        execution_time = time.time() - start_time
        
        return {
            'method': 'Enhanced Method',
            'predicted_next': prediction['predicted_next'],
            'confidence': prediction['confidence'],
            'execution_time': execution_time
        }
    
    def comprehensive_comparison(self, test_ranges: List[Tuple[int, int]]) -> Dict:
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ø´Ø§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚Ø§Øª Ù…Ø®ØªÙ„ÙØ©"""
        
        print("ğŸ”¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø·Ø±ÙŠÙ‚ØªÙŠÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØªÙŠÙ†")
        print("=" * 60)
        
        all_results = {
            'Basic Method': {'total_correct': 0, 'total_tests': 0, 'total_time': 0, 'total_confidence': 0, 'details': []},
            'Enhanced Method': {'total_correct': 0, 'total_tests': 0, 'total_time': 0, 'total_confidence': 0, 'details': []}
        }
        
        for start_range, count in test_ranges:
            print(f"\nğŸ¯ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø·Ø§Ù‚: {start_range}+ ({count} Ø£Ø¹Ø¯Ø§Ø¯)")
            print("-" * 40)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
            test_primes = generate_primes(start_range, count)
            print(f"ğŸ“Š Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ÙØ¹Ù„ÙŠ: {test_primes[0]} Ø¥Ù„Ù‰ {test_primes[-1]}")
            
            # Ø§Ø®ØªØ¨Ø§Ø± ÙƒÙ„ Ø·Ø±ÙŠÙ‚Ø©
            for i, prime in enumerate(test_primes[:-1]):
                actual_next = test_primes[i + 1]
                
                # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
                basic_result = self.method_basic(prime)
                basic_correct = basic_result['predicted_next'] == actual_next
                basic_gap_error = abs(basic_result['predicted_next'] - actual_next)
                
                # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
                enhanced_result = self.method_enhanced(prime)
                enhanced_correct = enhanced_result['predicted_next'] == actual_next
                enhanced_gap_error = abs(enhanced_result['predicted_next'] - actual_next)
                
                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                all_results['Basic Method']['total_tests'] += 1
                all_results['Enhanced Method']['total_tests'] += 1
                
                if basic_correct:
                    all_results['Basic Method']['total_correct'] += 1
                if enhanced_correct:
                    all_results['Enhanced Method']['total_correct'] += 1
                
                all_results['Basic Method']['total_time'] += basic_result['execution_time']
                all_results['Enhanced Method']['total_time'] += enhanced_result['execution_time']
                
                all_results['Basic Method']['total_confidence'] += basic_result['confidence']
                all_results['Enhanced Method']['total_confidence'] += enhanced_result['confidence']
                
                # Ø­ÙØ¸ Ø§Ù„ØªÙØ§ØµÙŠÙ„
                all_results['Basic Method']['details'].append({
                    'prime': prime,
                    'predicted': basic_result['predicted_next'],
                    'actual': actual_next,
                    'correct': basic_correct,
                    'gap_error': basic_gap_error,
                    'confidence': basic_result['confidence'],
                    'time': basic_result['execution_time']
                })
                
                all_results['Enhanced Method']['details'].append({
                    'prime': prime,
                    'predicted': enhanced_result['predicted_next'],
                    'actual': actual_next,
                    'correct': enhanced_correct,
                    'gap_error': enhanced_gap_error,
                    'confidence': enhanced_result['confidence'],
                    'time': enhanced_result['execution_time']
                })
                
                # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                basic_status = "âœ…" if basic_correct else "âŒ"
                enhanced_status = "âœ…" if enhanced_correct else "âŒ"
                
                print(f"  {prime} â†’ {actual_next}:")
                print(f"    Basic:    {basic_status} {basic_result['predicted_next']} (Ø«Ù‚Ø©: {basic_result['confidence']:.2f})")
                print(f"    Enhanced: {enhanced_status} {enhanced_result['predicted_next']} (Ø«Ù‚Ø©: {enhanced_result['confidence']:.2f})")
        
        return all_results
    
    def analyze_results(self, results: Dict) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"""
        
        print("\nğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù†ØªØ§Ø¦Ø¬")
        print("=" * 50)
        
        analysis = {}
        
        for method, data in results.items():
            accuracy = data['total_correct'] / data['total_tests'] if data['total_tests'] > 0 else 0
            avg_time = data['total_time'] / data['total_tests'] if data['total_tests'] > 0 else 0
            avg_confidence = data['total_confidence'] / data['total_tests'] if data['total_tests'] > 0 else 0
            avg_gap_error = np.mean([d['gap_error'] for d in data['details']]) if data['details'] else 0
            
            analysis[method] = {
                'accuracy': accuracy,
                'correct_predictions': data['total_correct'],
                'total_tests': data['total_tests'],
                'average_time': avg_time,
                'average_confidence': avg_confidence,
                'average_gap_error': avg_gap_error
            }
            
            print(f"\nğŸ¯ {method}:")
            print(f"   ğŸ“Š Ø§Ù„Ø¯Ù‚Ø©: {accuracy:.1%} ({data['total_correct']}/{data['total_tests']})")
            print(f"   âš¡ Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆÙ‚Øª: {avg_time:.4f}s")
            print(f"   ğŸ¯ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {avg_confidence:.2f}")
            print(f"   ğŸ“ Ù…ØªÙˆØ³Ø· Ø®Ø·Ø£ Ø§Ù„ÙØ¬ÙˆØ©: {avg_gap_error:.2f}")
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ÙØ¶Ù„
        if analysis['Basic Method']['accuracy'] > analysis['Enhanced Method']['accuracy']:
            winner = 'Basic Method'
        elif analysis['Enhanced Method']['accuracy'] > analysis['Basic Method']['accuracy']:
            winner = 'Enhanced Method'
        else:
            # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ø§Ø¯Ù„ØŒ Ù†Ø®ØªØ§Ø± Ø§Ù„Ø£Ø³Ø±Ø¹
            if analysis['Basic Method']['average_time'] < analysis['Enhanced Method']['average_time']:
                winner = 'Basic Method'
            else:
                winner = 'Enhanced Method'
        
        print(f"\nğŸ† Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ÙØ§Ø¦Ø²Ø©: {winner}")
        
        return analysis, winner
    
    def plot_detailed_comparison(self, results: Dict, analysis: Dict):
        """Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© ØªÙØµÙŠÙ„ÙŠØ©"""
        
        methods = list(analysis.keys())
        accuracies = [analysis[m]['accuracy'] * 100 for m in methods]
        times = [analysis[m]['average_time'] * 1000 for m in methods]  # milliseconds
        confidences = [analysis[m]['average_confidence'] * 100 for m in methods]
        gap_errors = [analysis[m]['average_gap_error'] for m in methods]
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        colors = ['#2E86AB', '#A23B72']  # Ø£Ø²Ø±Ù‚ ÙˆØ£Ø­Ù…Ø±
        
        # Ø±Ø³Ù… Ø§Ù„Ø¯Ù‚Ø©
        bars1 = axes[0, 0].bar(methods, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=1)
        axes[0, 0].set_title('Prediction Accuracy Comparison\nÙ…Ù‚Ø§Ø±Ù†Ø© Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤', fontsize=12, fontweight='bold')
        axes[0, 0].set_ylabel('Accuracy (%)')
        axes[0, 0].set_ylim(0, 105)
        axes[0, 0].grid(True, alpha=0.3)
        
        for bar, acc in zip(bars1, accuracies):
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                           f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        # Ø±Ø³Ù… Ø§Ù„ÙˆÙ‚Øª
        bars2 = axes[0, 1].bar(methods, times, color=colors, alpha=0.8, edgecolor='black', linewidth=1)
        axes[0, 1].set_title('Execution Time Comparison\nÙ…Ù‚Ø§Ø±Ù†Ø© ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°', fontsize=12, fontweight='bold')
        axes[0, 1].set_ylabel('Time (ms)')
        axes[0, 1].grid(True, alpha=0.3)
        
        for bar, time_val in zip(bars2, times):
            axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2,
                           f'{time_val:.2f}ms', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        # Ø±Ø³Ù… Ø§Ù„Ø«Ù‚Ø©
        bars3 = axes[1, 0].bar(methods, confidences, color=colors, alpha=0.8, edgecolor='black', linewidth=1)
        axes[1, 0].set_title('Confidence Level Comparison\nÙ…Ù‚Ø§Ø±Ù†Ø© Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©', fontsize=12, fontweight='bold')
        axes[1, 0].set_ylabel('Confidence (%)')
        axes[1, 0].set_ylim(0, 105)
        axes[1, 0].grid(True, alpha=0.3)
        
        for bar, conf in zip(bars3, confidences):
            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                           f'{conf:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        # Ø±Ø³Ù… Ø®Ø·Ø£ Ø§Ù„ÙØ¬ÙˆØ©
        bars4 = axes[1, 1].bar(methods, gap_errors, color=colors, alpha=0.8, edgecolor='black', linewidth=1)
        axes[1, 1].set_title('Gap Error Comparison\nÙ…Ù‚Ø§Ø±Ù†Ø© Ø®Ø·Ø£ Ø§Ù„ÙØ¬ÙˆØ©', fontsize=12, fontweight='bold')
        axes[1, 1].set_ylabel('Average Gap Error')
        axes[1, 1].grid(True, alpha=0.3)
        
        for bar, error in zip(bars4, gap_errors):
            axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                           f'{error:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        plt.tight_layout()
        plt.savefig('final_methods_comparison.png', dpi=300, bbox_inches='tight')
        print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù…: final_methods_comparison.png")
        
        return fig
    
    def create_detailed_report(self, results: Dict, analysis: Dict, winner: str):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„"""
        
        report = f"""
# ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ÙŠÙ† Ø·Ø±ÙŠÙ‚ØªÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤
# Final Comparison Report Between Prediction Methods

## Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© / Overall Results

### Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© / Basic Method:
- Ø§Ù„Ø¯Ù‚Ø© / Accuracy: {analysis['Basic Method']['accuracy']:.1%}
- Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø© / Correct Predictions: {analysis['Basic Method']['correct_predictions']}/{analysis['Basic Method']['total_tests']}
- Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆÙ‚Øª / Average Time: {analysis['Basic Method']['average_time']:.4f}s
- Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø© / Average Confidence: {analysis['Basic Method']['average_confidence']:.2f}
- Ù…ØªÙˆØ³Ø· Ø®Ø·Ø£ Ø§Ù„ÙØ¬ÙˆØ© / Average Gap Error: {analysis['Basic Method']['average_gap_error']:.2f}

### Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© / Enhanced Method:
- Ø§Ù„Ø¯Ù‚Ø© / Accuracy: {analysis['Enhanced Method']['accuracy']:.1%}
- Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø© / Correct Predictions: {analysis['Enhanced Method']['correct_predictions']}/{analysis['Enhanced Method']['total_tests']}
- Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆÙ‚Øª / Average Time: {analysis['Enhanced Method']['average_time']:.4f}s
- Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø© / Average Confidence: {analysis['Enhanced Method']['average_confidence']:.2f}
- Ù…ØªÙˆØ³Ø· Ø®Ø·Ø£ Ø§Ù„ÙØ¬ÙˆØ© / Average Gap Error: {analysis['Enhanced Method']['average_gap_error']:.2f}

## Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© / Final Result:
ğŸ† Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ÙØ§Ø¦Ø²Ø© / Winner: {winner}

## Ø§Ù„ØªÙˆØµÙŠØ§Øª / Recommendations:
"""
        
        if winner == 'Basic Method':
            report += """
- Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø£ÙØ¶Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ø§Ù…
- Ø£Ø³Ø±Ø¹ ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ°
- Ø¯Ù‚Ø© Ù…Ù…ØªØ§Ø²Ø© Ù…Ø¹ Ø¨Ø³Ø§Ø·Ø© ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
"""
        else:
            report += """
- Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ø£ÙØ¶Ù„ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
- Ù…Ø³ØªÙˆÙ‰ Ø«Ù‚Ø© Ø£Ø¹Ù„Ù‰
- Ù…Ø¹Ø§Ù…Ù„Ø§Øª ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ© Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹
"""
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        with open('final_comparison_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: final_comparison_report.md")
        
        return report

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    print("ğŸš€ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ÙŠÙ† Ø·Ø±ÙŠÙ‚ØªÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤")
    print("=" * 60)
    
    comparator = FinalMethodsComparison()
    
    # Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    test_ranges = [
        (5, 15),    # Ø£Ø¹Ø¯Ø§Ø¯ Ø£ÙˆÙ„ÙŠØ© ØµØºÙŠØ±Ø©
        (50, 10),   # Ø£Ø¹Ø¯Ø§Ø¯ Ø£ÙˆÙ„ÙŠØ© Ù…ØªÙˆØ³Ø·Ø©
        (100, 8),   # Ø£Ø¹Ø¯Ø§Ø¯ Ø£ÙˆÙ„ÙŠØ© ÙƒØ¨ÙŠØ±Ø©
    ]
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    results = comparator.comprehensive_comparison(test_ranges)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    analysis, winner = comparator.analyze_results(results)
    
    # Ø±Ø³Ù… Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    fig = comparator.plot_detailed_comparison(results, analysis)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report = comparator.create_detailed_report(results, analysis, winner)
    
    print("\n" + "="*60)
    print("ğŸ‰ Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©!")
    print("="*60)
    
    return results, analysis, winner

if __name__ == "__main__":
    results, analysis, winner = main()
